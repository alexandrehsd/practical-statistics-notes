{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0edc5ffe",
   "metadata": {},
   "source": [
    "# Chapter 06 - Statistical Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52a635ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643c2a92",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fd5c60",
   "metadata": {},
   "source": [
    "The idea behind KNN is pretty simple:\n",
    "\n",
    "1. Find K records that have similar features (i.e., similar predictor values).\n",
    "2. For classification, find out what the majority class is among those similar records and assign that class to the new record.\n",
    "3. For prediction (also called KNN regression), find the average among those similar records, and predict that average for the new record."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7297ed5d",
   "metadata": {},
   "source": [
    "### A Small Example: Predicting Loan Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "204a7095",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAN200_CSV = '../data/loan200.csv'\n",
    "LOAN3000_CSV = '../data/loan3000.csv'\n",
    "LOAN_DATA_CSV = '../data/loan_data.csv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffd413bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>payment_inc_ratio</th>\n",
       "      <th>dti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>target</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>22.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>default</td>\n",
       "      <td>5.46933</td>\n",
       "      <td>21.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paid off</td>\n",
       "      <td>6.90294</td>\n",
       "      <td>8.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid off</td>\n",
       "      <td>11.14800</td>\n",
       "      <td>1.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>default</td>\n",
       "      <td>3.72120</td>\n",
       "      <td>10.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    outcome  payment_inc_ratio    dti\n",
       "0    target            9.00000  22.50\n",
       "1   default            5.46933  21.33\n",
       "2  paid off            6.90294   8.97\n",
       "3  paid off           11.14800   1.83\n",
       "4   default            3.72120  10.81"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan200 = pd.read_csv(LOAN200_CSV)\n",
    "loan200.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82fdc383",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['payment_inc_ratio', 'dti']\n",
    "outcome = 'outcome'\n",
    "\n",
    "newloan = loan200.loc[0:0, predictors]\n",
    "X = loan200.loc[1:, predictors]\n",
    "y = loan200.loc[1:, outcome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a377ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45 0.55]]\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X, y)\n",
    "knn.predict(newloan)\n",
    "print(knn.predict_proba(newloan))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1081f4c",
   "metadata": {},
   "source": [
    "The probability of belonging to a class is given by the proportion of neighbors from that class among K.  In the preceding example, this probability of default would have been estimated at 9/20, or 0.45."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cdce2d",
   "metadata": {},
   "source": [
    "### Distance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89708216",
   "metadata": {},
   "source": [
    "In measuring distance between two vectors, we must watch out for difference in scale between variables. Features that have a higher order of magnitude will likely dominate and have almost all influence over the algorithm. To mitigate this problem, we can use the standardized version of the features, such as the Z-Score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b47f412",
   "metadata": {},
   "source": [
    "### Choosing K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff81eac",
   "metadata": {},
   "source": [
    "Generally speaking, if K is too low (close to 1), we may be overfitting; including the noise in the data. Higher values of K provide smoothing that reduces the risk of overfitting in the training data. On the other hand, if K is too high, we may oversmooth the data and miss out on KNN's ability to capture the local structure in the data, one of its main advantages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf526b1",
   "metadata": {},
   "source": [
    "The K that best balances between overfitting and oversmoothing is typically determined by accuracy metrics and, in particular, accuracy with holdout or validation data. There is no general rule about the best K—it depends greatly on the nature of the data. For highly structured data with little noise, smaller values of K work best. Borrowing a term from the signal processing community, this type of data is sometimes referred to as having a high signal-to-noise ratio (SNR). Examples of data with a typically high SNR are data sets for handwriting and speech recognition. For noisy data with less structure (data with a low SNR), such as the loan data, larger values of K are appropriate. Typically, values of K fall in the range 1 to 20. Often, an odd number is chosen to avoid ties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1f8acc",
   "metadata": {},
   "source": [
    "### KNN as a Feature Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6c2f81",
   "metadata": {},
   "source": [
    "s. In practical model fitting, however, KNN can be used to add “local\n",
    "knowledge” in a staged process with other classification techniques:\n",
    "\n",
    "1. KNN is run on the data, and for each record, a classification (or quasi-probability of a class) is derived.\n",
    "2. That result is added as a new feature to the record, and another classification method is then run on the data. The original predictor variables are thus used twice.\n",
    "\n",
    "At first you might wonder whether this process, since it uses some predictors twice, causes a problem with multicollinearity (see “Multicollinearity” on page 172). This is not an issue, since the information being incorporated into the second-stage model is highly local, derived only from a few nearby records, and is therefore additional information and not redundant.\n",
    "\n",
    "You can think of this staged use of KNN as a form of ensemble learning, in which multiple predictive modeling methods are used in conjunction with one another. It can also be considered as a form of feature engineering in which the aim is to derive features (predictor variables) that have predictive power. Often this involves some manual review of the data; KNN gives a fairly automatic way to do this.\n",
    "\n",
    "For example, consider the King County housing data. In pricing a home for sale, a realtor will base the price on similar homes recently sold, known as “comps.” In essence, realtors are doing a manual version of KNN: by looking at the sale prices of similar homes, they can estimate what a home will sell for. We can create a new fea‐ ture for a statistical model to mimic the real estate professional by applying KNN to recent sales. The predicted value is the sales price, and the existing predictor variables could include location, total square feet, type of structure, lot size, and number of bedrooms and bathrooms. The new predictor variable (feature) that we add via KNN is the KNN predictor for each record (analogous to the realtors’ comps). Since we are predicting a numerical value, the average of the K-Nearest Neighbors is used instead of a majority vote (known as KNN regression).\n",
    "\n",
    "Similarly, for the loan data, we can create features that represent different aspects of the loan process. For example, the following code would build a feature that represents a borrower’s creditworthiness:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc36fc84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    45342.000000\n",
       "mean         0.498902\n",
       "std          0.128736\n",
       "min          0.050000\n",
       "25%          0.400000\n",
       "50%          0.500000\n",
       "75%          0.600000\n",
       "max          1.000000\n",
       "Name: borrower_score, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data = pd.read_csv(LOAN_DATA_CSV)\n",
    "\n",
    "predictors = ['dti', 'revol_bal', 'revol_util', 'open_acc',\n",
    " 'delinq_2yrs_zero', 'pub_rec_zero']\n",
    "outcome = 'outcome'\n",
    "\n",
    "X = loan_data[predictors]\n",
    "y = loan_data[outcome]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=20)\n",
    "knn.fit(X, y)\n",
    "\n",
    "loan_data['borrower_score'] = knn.predict_proba(X)[:, 1]\n",
    "loan_data['borrower_score'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb73cf5f",
   "metadata": {},
   "source": [
    "The result is a feature that predicts the likelihood a borrower will default based on his credit history."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
